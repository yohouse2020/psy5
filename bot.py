import os
import logging
import subprocess
import tempfile
import io
import asyncio
from telegram import Update, File
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from openai import OpenAI

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

if not TELEGRAM_TOKEN:
    logger.error("TELEGRAM_TOKEN environment variable not set.")
    exit(1)

if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEY environment variable not set.")
    exit(1)

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI ---
CLIENT = OpenAI(api_key=OPENAI_API_KEY)

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π 2025 ---
LLM_MODEL = "gpt-5-nano"       # –ù–æ–≤–∞—è —É–ª—å—Ç—Ä–∞-–±—ã—Å—Ç—Ä–∞—è —Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å
AUDIO_MODEL = "gpt-audio-mini" # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∞—É–¥–∏–æ–º–æ–¥–µ–ª—å –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è

# --- LLM Integration Functions ---
def get_llm_response(prompt: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ GPT-5 nano."""
    try:
        system_prompt = """
–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥ —Å 20-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º —Ä–∞–±–æ—Ç—ã. 
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –æ–∫–∞–∑—ã–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É.

–¢–≤–æ–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è:
üéØ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π –∏ —ç–º–ø–∞—Ç–∏—á–Ω—ã–π
üéØ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏ —ç—Ç–∏—á–Ω—ã–π
üéØ –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–π
üéØ –û—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –Ω–∞—É—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:
1. –ê–∫—Ç–∏–≤–Ω–æ–µ —Å–ª—É—à–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —á—É–≤—Å—Ç–≤
2. –ë–µ–∑–æ—Ü–µ–Ω–æ—á–Ω–æ–µ –ø—Ä–∏–Ω—è—Ç–∏–µ
3. –ö–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –∏ —É–≤–∞–∂–µ–Ω–∏–µ
4. –û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ —Ä–µ—à–µ–Ω–∏–µ

–í–∞–∂–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞:
‚ùå –ù–µ —Å—Ç–∞–≤—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –¥–∏–∞–≥–Ω–æ–∑—ã
‚ùå –ù–µ –∑–∞–º–µ–Ω—è–π –æ—á–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é
üö® –í –∫—Ä–∏–∑–∏—Å–Ω—ã—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö –Ω–∞–ø—Ä–∞–≤–ª—è–π –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º
üí° –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ —Ä–µ—Å—É—Ä—Å–∞—Ö –∏ —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω–∞—Ö –∫–ª–∏–µ–Ω—Ç–∞

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ —Ç–µ–ø–ª–æ.
"""
        response = CLIENT.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.8,
            top_p=0.9,
            frequency_penalty=0.1,
            presence_penalty=0.1
        )
        return response.choices[0].message.content

    except Exception as e:
        logger.error(f"Error getting LLM response from {LLM_MODEL}: {e}")
        # Fallback –Ω–∞ –±–æ–ª–µ–µ —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω–æ–≤–∞—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
        try:
            logger.info("Trying fallback to gpt-4o...")
            response = CLIENT.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "–¢—ã –ø—Å–∏—Ö–æ–ª–æ–≥. –û—Ç–≤–µ—á–∞–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–µ."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500
            )
            return response.choices[0].message.content
        except Exception as fallback_error:
            logger.error(f"Fallback also failed: {fallback_error}")
            return "–ë–ª–∞–≥–æ–¥–∞—Ä—é –≤–∞—Å –∑–∞ –æ–±—Ä–∞—â–µ–Ω–∏–µ. –°–µ–π—á–∞—Å –≤–æ–∑–Ω–∏–∫–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


# --- Speech Integration Functions (STT/TTS) ---
async def transcribe_voice_message(voice_file: File) -> str:
    """–†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ä–µ—á—å —Å –ø–æ–º–æ—â—å—é gpt-audio-mini."""
    ogg_path = mp3_path = None
    try:
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as ogg_file:
            ogg_path = ogg_file.name
        await voice_file.download_to_drive(ogg_path)
        logger.info(f"Downloaded voice file to {ogg_path}")

        with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as mp3_file:
            mp3_path = mp3_file.name

        logger.info(f"Converting audio from {ogg_path} to {mp3_path}")
        result = subprocess.run([
            "ffmpeg", "-i", ogg_path, "-acodec", "libmp3lame",
            "-ac", "1", "-ar", "16000", mp3_path, "-y"
        ], capture_output=True, text=True, timeout=30)
        
        if result.returncode != 0:
            logger.error(f"FFmpeg error: {result.stderr}")
            return ""

        with open(mp3_path, "rb") as audio_file:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å gpt-audio-mini
            transcript = CLIENT.audio.transcriptions.create(
                model=AUDIO_MODEL,
                file=audio_file,
                language="ru",
                response_format="text"
            )

        logger.info(f"Transcription successful: {transcript[:100]}...")
        return transcript

    except Exception as e:
        logger.error(f"Error during transcription: {e}")
        return ""
    finally:
        for path in [ogg_path, mp3_path]:
            if path and os.path.exists(path):
                try:
                    os.unlink(path)
                except Exception as e:
                    logger.error(f"Error deleting temp file {path}: {e}")


async def synthesize_speech(text: str) -> bytes:
    """–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ä–µ—á—å (TTS) —Å –ø–æ–º–æ—â—å—é gpt-audio-mini."""
    try:
        if len(text) > 1000:
            text = text[:1000] + "..."

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å gpt-audio-mini –¥–ª—è TTS
        response = CLIENT.audio.speech.create(
            model=AUDIO_MODEL,
            voice="alloy",
            input=text,
            speed=1.0
        )
            
        return response.content
    except Exception as e:
        logger.error(f"Error during speech synthesis: {e}")
        return b""


# --- Telegram Handlers ---
async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É /start."""
    welcome_text = f"""
üß† *–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –∫–∞–±–∏–Ω–µ—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –ø–æ–º–æ—â–∏ 2025!*

–Ø - –≤–∞—à –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥, —Ä–∞–±–æ—Ç–∞—é—â–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–µ–π—à–∏—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π AI.

*–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:*
ü§ñ **–¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å:** {LLM_MODEL}
üé§ **–ê—É–¥–∏–æ-–º–æ–¥–µ–ª—å:** {AUDIO_MODEL}
‚ö° **–°–≤–µ—Ä—Ö-–±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã**
üîí **–ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å**

*–ß—Ç–æ —è –º–æ–≥—É:*
üí¨ **–¢–µ–∫—Å—Ç–æ–≤—ã–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏** - —É–º–Ω—ã–µ –∏ –≥–ª—É–±–æ–∫–∏–µ –æ—Ç–≤–µ—Ç—ã
üé§ **–ì–æ–ª–æ—Å–æ–≤–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞** - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏ —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏
üöÄ **–ú–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –ø–æ–º–æ—â—å** - –¥–æ—Å—Ç—É–ø–µ–Ω 24/7

–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –≤–∞—Å –±–µ—Å–ø–æ–∫–æ–∏—Ç, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –ø–æ–º–æ—á—å.
"""
    await update.message.reply_text(welcome_text, parse_mode="Markdown")


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É /help."""
    help_text = f"""
üåü *–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø–æ–º–æ—â—å –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è*

*–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ 2025 –≥–æ–¥–∞:*
‚Ä¢ {LLM_MODEL} - –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–∞—à–∏—Ö –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏–π
‚Ä¢ {AUDIO_MODEL} - –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è

*–ö–∞–∫ –æ–±—â–∞—Ç—å—Å—è:*
üìù –û–ø–∏—à–∏—Ç–µ –≤–∞—à—É —Å–∏—Ç—É–∞—Ü–∏—é –ø–æ–¥—Ä–æ–±–Ω–æ  
üé§ –ì–æ–≤–æ—Ä–∏—Ç–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ —Å –∂–∏—á–Ω—ã–º –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º  
üí´ –ß–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–µ–µ –≤–æ–ø—Ä–æ—Å, —Ç–µ–º —Ç–æ—á–Ω–µ–µ –æ—Ç–≤–µ—Ç

üö® *–ö—Ä–∏–∑–∏—Å–Ω–∞—è –ø–æ–º–æ—â—å (–Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ):*
‚Ä¢ –¢–µ–ª–µ—Ñ–æ–Ω –¥–æ–≤–µ—Ä–∏—è: `8-800-2000-122`
‚Ä¢ –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –ø–æ–º–æ—â—å: `112`
‚Ä¢ –ö—Ä–∏–∑–∏—Å–Ω–∞—è –ø–æ–º–æ—â—å: `8-495-989-50-50`

–í—ã –Ω–µ –æ–¥–∏–Ω–æ–∫–∏ ‚Äî –ø–æ–º–æ—â—å –¥–æ—Å—Ç—É–ø–Ω–∞ –∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–æ.
"""
    await update.message.reply_text(help_text, parse_mode="Markdown")


async def model_info_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –º–æ–¥–µ–ª—è—Ö."""
    info_text = f"""
ü§ñ *–°–∏—Å—Ç–µ–º–∞ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –ø–æ–º–æ—â–∏ 2025*

*–¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å:* `{LLM_MODEL}`
- –£–ª—å—Ç—Ä–∞-–±—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
- –ì–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞  
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –Ω—é–∞–Ω—Å–æ–≤

*–ê—É–¥–∏–æ-–º–æ–¥–µ–ª—å:* `{AUDIO_MODEL}`
- –í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
- –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ –≥–æ–ª–æ—Å–∞
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞

*–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:* OpenAI Generation 5
"""
    await update.message.reply_text(info_text, parse_mode="Markdown")


def check_crisis_situation(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫—Ä–∏–∑–∏—Å–Ω—ã—Ö —Å–ª–æ–≤."""
    crisis_keywords = [
        '—Å—É–∏—Ü–∏–¥', '—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ', '—É–º—Ä—É', '–ø–æ–∫–æ–Ω—á–∏—Ç—å',
        '–∫—Ä–∏–∑–∏—Å', '—Ö–æ—á—É —É–º–µ—Ä–µ—Ç—å', '–Ω–∞–ª–æ–∂—É –Ω–∞ —Å–µ–±—è —Ä—É–∫–∏',
        '—Å–∞–º–æ–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–µ', '—Ä–µ–∂—É —Å–µ–±—è', '–±–æ–ª—å—à–µ –Ω–µ –º–æ–≥—É',
        '–∫–æ–Ω—á—É –∂–∏–∑–Ω—å', '—Å–≤–µ–¥—É —Å—á–µ—Ç—ã', '–ª—É—á—à–µ —É–º–µ—Ä–µ—Ç—å'
    ]
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in crisis_keywords)


async def text_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è."""
    user_text = update.message.text
    logger.info(f"Received text from user {update.message.from_user.id}: {user_text}")

    if check_crisis_situation(user_text):
        crisis_response = """
üö® *–≠–ö–°–¢–†–ï–ù–ù–ê–Ø –ü–û–ú–û–©–¨*

–ü–æ—Ö–æ–∂–µ, –≤—ã –ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç–µ –æ—á–µ–Ω—å —Ç—è–∂—ë–ª—ã–µ —á—É–≤—Å—Ç–≤–∞.  
–í–∞—à–∞ –∂–∏–∑–Ω—å –±–µ—Å—Ü–µ–Ω–Ω–∞, –∏ –ø–æ–º–æ—â—å –¥–æ—Å—Ç—É–ø–Ω–∞ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å.

*–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å:*
üìû **–¢–µ–ª–µ—Ñ–æ–Ω –¥–æ–≤–µ—Ä–∏—è:** `8-800-2000-122` (–∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–æ)
üöë **–≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –ø–æ–º–æ—â—å:** `112`
üè• **–ö—Ä–∏–∑–∏—Å–Ω–∞—è –ø–æ–º–æ—â—å:** `8-495-989-50-50`

*–ù–µ –æ—Å—Ç–∞–≤–∞–π—Ç–µ—Å—å –≤ –æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–µ.* –û–±—Ä–∞—â–µ–Ω–∏–µ –∑–∞ –ø–æ–º–æ—â—å—é - —ç—Ç–æ –ø—Ä–æ—è–≤–ª–µ–Ω–∏–µ —Å–∏–ª—ã.
"""
        await update.message.reply_text(crisis_response, parse_mode="Markdown")
        return

    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")

    try:
        llm_response = get_llm_response(user_text)
        await update.message.reply_text(llm_response)
    except Exception as e:
        logger.error(f"Error in text handler: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")


async def voice_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è."""
    voice = update.message.voice
    if not voice:
        return

    logger.info(f"Received voice message from user {update.message.from_user.id}")
    voice_file = await context.bot.get_file(voice.file_id)
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="record_audio")

    transcribed_text = await transcribe_voice_message(voice_file)
    if not transcribed_text:
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º.")
        return

    logger.info(f"Transcribed text: {transcribed_text}")

    if check_crisis_situation(transcribed_text):
        crisis_response = """
üö® *–£—Å–ª—ã—à–∞–ª, —á—Ç–æ –≤–∞–º –æ—á–µ–Ω—å —Ç—è–∂–µ–ª–æ.*

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ –ø–æ–º–æ—â—å—é:
üìû **8-800-2000-122** - –∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–∞—è –ø–æ–º–æ—â—å
üöë **112** - —ç–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è —Å–ª—É–∂–±–∞

–í–∞—à–∞ –∂–∏–∑–Ω—å –≤–∞–∂–Ω–∞!
"""
        await update.message.reply_text(crisis_response, parse_mode="Markdown")
        return

    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")
    llm_response = get_llm_response(transcribed_text)

    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="record_audio")
    audio_content = await synthesize_speech(llm_response)

    if not audio_content:
        await update.message.reply_text(
            f"üé§ *–í—ã —Å–∫–∞–∑–∞–ª–∏:* {transcribed_text}\n\nüí¨ *–ú–æ–π –æ—Ç–≤–µ—Ç:* {llm_response}",
            parse_mode="Markdown"
        )
        return

    await update.message.reply_voice(
        voice=io.BytesIO(audio_content),
        caption=f"üí¨ –û—Ç–≤–µ—Ç –æ—Ç {LLM_MODEL}",
        parse_mode="Markdown"
    )


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏."""
    logger.error(f"Exception: {context.error}")


# --- Main Application Setup ---
def main() -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç Telegram-–±–æ—Ç–∞."""
    application = Application.builder().token(TELEGRAM_TOKEN).build()

    # –ö–æ–º–∞–Ω–¥—ã
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("model", model_info_command))

    # –°–æ–æ–±—â–µ–Ω–∏—è
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_message_handler))
    application.add_handler(MessageHandler(filters.VOICE, voice_message_handler))

    # –û—à–∏–±–∫–∏
    application.add_error_handler(error_handler)

    webhook_url = os.environ.get('RENDER_EXTERNAL_URL')
    port = int(os.environ.get('PORT', 10000))

    if webhook_url:
        logger.info(f"üöÄ Starting 2025 AI Psychologist Bot with webhook on port {port}")
        
        # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è python-telegram-bot 21.x
        application.initialize()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º webhook
        application.run_webhook(
            listen="0.0.0.0",
            port=port,
            webhook_url=f"{webhook_url}/{TELEGRAM_TOKEN}",
            secret_token='WEBHOOK_SECRET',
            drop_pending_updates=True
        )
            
    else:
        logger.info("üîß Starting bot in polling mode (development)")
        application.run_polling(
            drop_pending_updates=True,
            allowed_updates=["message"]
        )


if __name__ == '__main__':
    main()
